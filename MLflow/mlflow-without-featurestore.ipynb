{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa6f9624-bd6b-4b4c-a56f-0506f180aca0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### MLflow introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afb36444-2ec6-4389-8f2d-71fc3e8c3cd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####0. SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3aaebee-83de-4f02-89aa-40665b4faf12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#install latest version of sklearn\n",
    "%pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe0f802b-3226-4ffd-b5a5-af2a667098f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6320b60e-8efe-477d-9127-2af077b483dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Step 1. Importing the desired libraries and defining few constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43105686-92b8-4958-847f-ec5dc7bb40a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureStoreClient\n",
    "from databricks.feature_store import FeatureLookup\n",
    "import typing\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9e59154-d38b-4a42-9478-04552ead5c69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Name of experiment where we will track all the different model training runs.\n",
    "EXPERIMENT_NAME = \"Bank_Customer_Churn_Analysis\"\n",
    "#Name of the model\n",
    "MODEL_NAME = \"random_forest_classifier\"\n",
    "#This is the name for the entry in model registry\n",
    "MODEL_REGISTRY_NAME = \"Bank_Customer_Churn\"\n",
    "#The email you use to authenticate in the Databricks workspace\n",
    "USER_EMAIL = \"samuel.hmariam@shewit.co.uk\"\n",
    "#Location where the MLflow experiement will be listed in user workspace\n",
    "EXPERIMENT_NAME = f\"/Users/{USER_EMAIL}/{EXPERIMENT_NAME}\"\n",
    "# we have all the features backed into a Delta table so we will read directly\n",
    "FEATURE_TABLE = \"bank_churn_analysis.bank_customer_features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "470c03b4-b6fa-4701-a6a6-6772f4ffeb91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Step 2. Build a simplistic model that uses the feature store table as its source for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "790de63f-3738-4a49-8c45-18b327111c86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set experiment name\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run():  \n",
    "  TEST_SIZE = 0.20\n",
    "  \n",
    "  # Now we will read the data directly from the feature table\n",
    "  training_df = spark.table(FEATURE_TABLE)\n",
    "  \n",
    "  # convert the dataset to pandas so that we can fit sklearn RandomForestClassifier on it\n",
    "  train_df = training_df.toPandas()\n",
    "  \n",
    "  # The train_df represents the input dataframe that has all the feature columns along with the new raw input in the form of training_df.\n",
    "  X = train_df.drop(['Exited'], axis=1)\n",
    "  y = train_df['Exited']\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=54, stratify=y)\n",
    "  \n",
    "  # here we are not doing any hyperparameter tuning however.\n",
    "  model = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "  signature = mlflow.models.signature.infer_signature(X_train, model.predict(X_train))\n",
    "  \n",
    "  predictions = model.predict(X_test)\n",
    "  fpr, tpr, _ = metrics.roc_curve(y_test, predictions, pos_label=1)\n",
    "  auc = metrics.auc(fpr, tpr)\n",
    "  accuracy = metrics.accuracy_score(y_test, predictions)\n",
    " \n",
    "  # get the calculated feature importances.\n",
    "  importances = dict(zip(model.feature_names_in_, model.feature_importances_))  \n",
    "  # log artifact\n",
    "  mlflow.log_dict(importances, \"feature_importances.json\")\n",
    "  # log metrics\n",
    "  mlflow.log_metric(\"auc\", auc)\n",
    "  mlflow.log_metric(\"accuracy\", accuracy)\n",
    "  # log parameters\n",
    "  mlflow.log_param(\"split_size\", TEST_SIZE)\n",
    "  mlflow.log_params(model.get_params())\n",
    "  # set tag\n",
    "  mlflow.set_tag(MODEL_NAME, \"mlflow demo\")\n",
    "  # log the model itself in mlflow tracking server\n",
    "  mlflow.sklearn.log_model(model, MODEL_NAME, signature=signature, input_example=X_train.iloc[:4, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b8ba209-0252-48f9-a245-73e6eca368dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "#initialize the mlflow client\n",
    "client = MlflowClient()\n",
    "#get the experiment id \n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "#get the latest run id which will allow us to directly access the metrics, and attributes and all th einfo\n",
    "run_id = mlflow.search_runs(experiment_id, order_by=[\"start_time DESC\"]).head(1)[\"run_id\"].values[0]\n",
    "#now we will register the latest model into the model registry\n",
    "new_model_version = mlflow.register_model(f\"runs:/{run_id}/{MODEL_NAME}\", MODEL_REGISTRY_NAME)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "mlflow-without-featurestore",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
